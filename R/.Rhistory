?mvtnorm::rmvnorm
#the simulation function
simTrack = function(T, theta, gamma, Sigma, alpha){
require(mvtnorm)
#accumulators
x = matrix(NA, T, 2)
emp = matrix(NA, T-1, 2)
b = c()
#Initialize locations randomly
x[1, ] = mvtnorm::rmvnorm(1, c(0,0), Sigma)
x[2, ] = mvtnorm::rmvnorm(1, x[1,], Sigma)
#Initialize behavioral state
b[1] = rbinom(1, 1, 0.5) + 1
#Process equation
for(i in 2:(T-1)){
#evolve states
b[i] = rbinom(1, 1, alpha[b[i-1]]) + 1
#the idea is that a success is defined as being in state 2, and a failure being
#in state 1. So we want the first alpha probability here to be low, since it
#is the probability of not switching to state 2 given you were in state 1.
#evolve movement process
emp[i,1] = cos(theta[b[i]]) * (x[i,1] - x[i-1,1]) + sin(theta[b[i]]) * (x[i,2] - x[i-1,2])
emp[i,2] = -sin(theta[b[i]]) * (x[i,1] - x[i-1,1]) + cos(theta[b[i]]) * (x[i,2] - x[i-1,2])
#add random error
x[i+1,] = mvtnorm::rmvnorm(1, x[i,] + emp[i,] * gamma[b[i]], Sigma)
}
#Get the last behavioral state
b[T] = rbinom(1, 1, alpha[b[T-1]]) + 1
dat = data.frame(lon=x[,1], lat = x[,2], b)
}
matrix(c(0.8,0.2,0.1,0.9),nrow=2)
matrix(c(0.8,0.1,0.2,0.9),nrow=2)
#the simulation function
simTrack = function(T=1000, theta=c(0,pi), gamma=c(0.7,0.2),
Sigma=matrix(c(0.2*0.2,0,0,0.1*0.1),nrow=2),
alpha=matrix(c(0.8,0.1,0.2,0.9),nrow=2)){
require(mvtnorm)
#accumulators
x = matrix(NA, T, 2)
emp = matrix(NA, T-1, 2)
b = c()
#Initialize locations randomly
x[1, ] = mvtnorm::rmvnorm(1, c(0,0), Sigma)
x[2, ] = mvtnorm::rmvnorm(1, x[1,], Sigma)
#Initialize behavioral state
b[1] = rbinom(1, 1, 0.5) + 1
#Process equation
for(i in 2:(T-1)){
#evolve states
b[i] = rbinom(1, 1, alpha[b[i-1]]) + 1
#the idea is that a success is defined as being in state 2, and a failure being
#in state 1. So we want the first alpha probability here to be low, since it
#is the probability of not switching to state 2 given you were in state 1.
#evolve movement process
emp[i,1] = cos(theta[b[i]]) * (x[i,1] - x[i-1,1]) + sin(theta[b[i]]) * (x[i,2] - x[i-1,2])
emp[i,2] = -sin(theta[b[i]]) * (x[i,1] - x[i-1,1]) + cos(theta[b[i]]) * (x[i,2] - x[i-1,2])
#add random error
x[i+1,] = mvtnorm::rmvnorm(1, x[i,] + emp[i,] * gamma[b[i]], Sigma)
}
#Get the last behavioral state
b[T] = rbinom(1, 1, alpha[b[T-1]]) + 1
dat = data.frame(lon=x[,1], lat = x[,2], b)
}
test = simTrack(1000)
#the simulation function
simTrack = function(T=1000, theta=c(0,pi), gamma=c(0.7,0.2),
Sigma=matrix(c(0.2*0.2,0,0,0.1*0.1),nrow=2),
alpha=matrix(c(0.8,0.1,0.2,0.9),nrow=2)){
#accumulators
x = matrix(NA, T, 2)
emp = matrix(NA, T-1, 2)
b = c()
#Initialize locations randomly
x[1, ] = mvtnorm::rmvnorm(1, c(0,0), Sigma)
x[2, ] = mvtnorm::rmvnorm(1, x[1,], Sigma)
#Initialize behavioral state
b[1] = rbinom(1, 1, 0.5) + 1
#Process equation
for(i in 2:(T-1)){
#evolve states
b[i] = rbinom(1, 1, alpha[b[i-1]]) + 1
#the idea is that a success is defined as being in state 2, and a failure being
#in state 1. So we want the first alpha probability here to be low, since it
#is the probability of not switching to state 2 given you were in state 1.
#evolve movement process
emp[i,1] = cos(theta[b[i]]) * (x[i,1] - x[i-1,1]) + sin(theta[b[i]]) * (x[i,2] - x[i-1,2])
emp[i,2] = -sin(theta[b[i]]) * (x[i,1] - x[i-1,1]) + cos(theta[b[i]]) * (x[i,2] - x[i-1,2])
#add random error
x[i+1,] = mvtnorm::rmvnorm(1, x[i,] + emp[i,] * gamma[b[i]], Sigma)
}
#Get the last behavioral state
b[T] = rbinom(1, 1, alpha[b[T-1]]) + 1
dat = data.frame(lon=x[,1], lat = x[,2], b)
}
test=simTrack(1000)
test
simTrack(500)
#the simulation function
simTrack = function(T=500, theta=c(0,pi), gamma=c(0.7,0.2),
Sigma=matrix(c(0.2*0.2,0,0,0.1*0.1),nrow=2),
alpha=matrix(c(0.8,0.1,0.2,0.9),nrow=2)){
#accumulators
x = matrix(NA, T, 2)
emp = matrix(NA, T-1, 2)
b = c()
#Initialize locations randomly
x[1, ] = mvtnorm::rmvnorm(1, c(0,0), Sigma)
x[2, ] = mvtnorm::rmvnorm(1, x[1,], Sigma)
#Initialize behavioral state
b[1] = rbinom(1, 1, 0.5) + 1
#Process equation
for(i in 2:(T-1)){
#evolve states
b[i] = rbinom(1, 1, alpha[b[i-1]]) + 1
#the idea is that a success is defined as being in state 2, and a failure being
#in state 1. So we want the first alpha probability here to be low, since it
#is the probability of not switching to state 2 given you were in state 1.
#evolve movement process
emp[i,1] = cos(theta[b[i]]) * (x[i,1] - x[i-1,1]) + sin(theta[b[i]]) * (x[i,2] - x[i-1,2])
emp[i,2] = -sin(theta[b[i]]) * (x[i,1] - x[i-1,1]) + cos(theta[b[i]]) * (x[i,2] - x[i-1,2])
#add random error
x[i+1,] = mvtnorm::rmvnorm(1, x[i,] + emp[i,] * gamma[b[i]], Sigma)
}
#Get the last behavioral state
b[T] = rbinom(1, 1, alpha[b[T-1]]) + 1
dat = data.frame(lon=x[,1], lat = x[,2], b)
return(dat)
}
simTrack(500)
require(swim)
data(blueshark)
fitSHMMM(blueshark, 6)
#the simulation function
simTrack = function(T=500, theta=c(0,pi), gamma=c(0.7,0.2),
Sigma=matrix(c(0.2*0.2,0,0,0.1*0.1),nrow=2),
alphas=c(0.8,0.9),nrow=2)){
#accumulators
x = matrix(NA, T, 2)
emp = matrix(NA, T-1, 2)
b = c()
alpha=c(1-alphas[1], alphas[2])
#Initialize locations randomly
x[1, ] = mvtnorm::rmvnorm(1, c(0,0), Sigma)
x[2, ] = mvtnorm::rmvnorm(1, x[1,], Sigma)
#Initialize behavioral state
b[1] = rbinom(1, 1, 0.5) + 1
#Process equation
for(i in 2:(T-1)){
#evolve states
b[i] = rbinom(1, 1, alpha[b[i-1]]) + 1
#the idea is that a success is defined as being in state 2, and a failure being
#in state 1. So we want the first alpha probability here to be low, since it
#is the probability of not switching to state 2 given you were in state 1.
#evolve movement process
emp[i,1] = cos(theta[b[i]]) * (x[i,1] - x[i-1,1]) + sin(theta[b[i]]) * (x[i,2] - x[i-1,2])
emp[i,2] = -sin(theta[b[i]]) * (x[i,1] - x[i-1,1]) + cos(theta[b[i]]) * (x[i,2] - x[i-1,2])
#add random error
x[i+1,] = mvtnorm::rmvnorm(1, x[i,] + emp[i,] * gamma[b[i]], Sigma)
}
#Get the last behavioral state
b[T] = rbinom(1, 1, alpha[b[T-1]]) + 1
dat = data.frame(lon=x[,1], lat = x[,2], b)
return(dat)
}
#the simulation function
simTrack = function(T=500, theta=c(0,pi), gamma=c(0.7,0.2),
Sigma=matrix(c(0.2*0.2,0,0,0.1*0.1),nrow=2),
alphas=c(0.8,0.9)){
#accumulators
x = matrix(NA, T, 2)
emp = matrix(NA, T-1, 2)
b = c()
alpha=c(1-alphas[1], alphas[2])
#Initialize locations randomly
x[1, ] = mvtnorm::rmvnorm(1, c(0,0), Sigma)
x[2, ] = mvtnorm::rmvnorm(1, x[1,], Sigma)
#Initialize behavioral state
b[1] = rbinom(1, 1, 0.5) + 1
#Process equation
for(i in 2:(T-1)){
#evolve states
b[i] = rbinom(1, 1, alpha[b[i-1]]) + 1
#the idea is that a success is defined as being in state 2, and a failure being
#in state 1. So we want the first alpha probability here to be low, since it
#is the probability of not switching to state 2 given you were in state 1.
#evolve movement process
emp[i,1] = cos(theta[b[i]]) * (x[i,1] - x[i-1,1]) + sin(theta[b[i]]) * (x[i,2] - x[i-1,2])
emp[i,2] = -sin(theta[b[i]]) * (x[i,1] - x[i-1,1]) + cos(theta[b[i]]) * (x[i,2] - x[i-1,2])
#add random error
x[i+1,] = mvtnorm::rmvnorm(1, x[i,] + emp[i,] * gamma[b[i]], Sigma)
}
#Get the last behavioral state
b[T] = rbinom(1, 1, alpha[b[T-1]]) + 1
dat = data.frame(lon=x[,1], lat = x[,2], b)
return(dat)
}
test=simTrack(500)
test$b
plot(test$lon~test$lat, col=ifelse(test$b==2, "red", "black"))
plot(test$lon~test$lat, col=ifelse(test$b==2, "red", "black"), type="o")
plot(test$lon~test$lat, col=ifelse(test$b==2, "red", "black"), type="o", pch=20)
test = simTrack(500, alphas=c(0.2,0.9))
plot(test$lon~test$lat, col=ifelse(test$b==2, "red", "black"), type="o", pch=20)
test$b
fitSWIM <- function(data, ts, model_type="SHMMM"){
#data input, n X 2 vector
#ts timestep (hours)
#interpolate the data to regular time intervals
delta = ts*60*60 #time step in seconds
t0 = data$date[1] #first time step
tT = data$date[length(data$date)] #the final date time
t = seq(t0, tT, by=delta) #all the time values for interpolation
iLoc <- cbind(approx(data$date, data$lon, xout = t)$y,
approx(data$date, data$lat, xout = t)$y)
#load TMB
requireNamespace("TMB", quietly=TRUE)
#compiling the c++ function
#compile("SHMMM.cpp", flags="-Wno-unused-variable")
#Loading the compiled c++ file into the R environment.
#dyn.load(dynlib("SHMMM")) #need to fix this for PCs (or non-macs)
#create a list of input data. The order must match the order in the c++ file!
space = 0:1
mu = c(0.5,0.5)
dats <- list(x = t(iLoc),
b=as.integer(space),
stateSpace=factor(space),
initDist=as.double(mu))
#create a list of input parameters. Again, order matters!
parameters <- list(logitTheta1=0, logitTheta2=0,
logitGamma1=0, logitGamma2=0,
logSdlat=0, logSdlon=0,
logA=matrix(log(1),ncol=1,nrow=2))
#Then make an objective function, the negative log likelihood to minimize.
obj <- MakeADFun(dats,parameters,
DLL="swim")
#Now we can pass the objective function and its derivatives into any regular R optimizer.
#We are using nlminb.
opt <- nlminb(obj$par,obj$fn,obj$gr)
#calculate the parameter results
srep <- summary(sdreport(obj))
#calculate the latent behavioral states with the Viterbi algorithm
states = obj$report()$states
#return the object and the parameter results
rslts <- list(regData = iLoc, obj=obj, parms=srep, states=states)
class(rslts) <- "swim" #set class for later (summary, print, and plot functions)
rslts
}
require(swim)
q()
